/*
  Author(s): Slawomir Bankowski
  Project: mlasaf
*/
package com.mlasaf.generates

import anorm.SQL
import com.mlasaf.dto.ColumnDetailDto
import com.mlasaf.loaders.CreateAlgorithmImplementationEntryOptions
import com.mlasaf.structures._

object GenerateDaoRestsEntry {

  /** */
  def main(args : Array[String]) = {
    val entryOptions = new GenerateEntryOptions(args);
    val jdbcString = entryOptions.jdbcString.getOrElse("")
    val jdbcUser = entryOptions.jdbcUser.getOrElse("")
    val jdbcPass = entryOptions.jdbcPass.getOrElse("")
    val jdbcDriver = entryOptions.jdbcDriver.getOrElse("")
    val baseFolder = entryOptions.baseFolder.getOrElse("")
    Class.forName(jdbcDriver);
    val generatedFileName = baseFolder + "ContextRestDao" + ".scala";
    val outputContent : java.io.BufferedWriter = new java.io.BufferedWriter(new java.io.FileWriter(generatedFileName));

    implicit val connmssql = java.sql.DriverManager.getConnection(jdbcString, jdbcUser, jdbcPass);
    val cols : List[ColumnDetailDto]=  SQL("select TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, case DATA_TYPE when 'bigint' then 'Long' when 'int' then 'Int' when 'nvarchar' then 'String' when 'varchar' then 'String' when 'datetime' then 'java.util.Date' when 'float' then 'Double'  else '' end as SCALA_TYPE from INFORMATION_SCHEMA.COLUMNS where TABLE_NAME not like 'DATABASE%'")
      .as(anorm.Macro.namedParser[ColumnDetailDto].*);
    val pkCols : List[ColumnDetailDto] =  SQL(" select TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, '' as SCALA_TYPE from INFORMATION_SCHEMA.KEY_COLUMN_USAGE where CONSTRAINT_NAME like 'PK%' and TABLE_NAME not like 'DATABASE%'")
      .as(anorm.Macro.namedParser[ColumnDetailDto].*);
    val fkCols : List[ColumnDetailDto] =  SQL(" select TABLE_NAME, COLUMN_NAME, ORDINAL_POSITION, '' as SCALA_TYPE from INFORMATION_SCHEMA.KEY_COLUMN_USAGE where CONSTRAINT_NAME like 'FK%' and TABLE_NAME not like 'DATABASE%'")
      .as(anorm.Macro.namedParser[ColumnDetailDto].*);

    outputContent.write("/*\n  Author(s): Slawomir Bankowski\n  Project: mlasaf\n  AUTOGENERATED CODE\n*/\npackage com.mlasaf.dao\n\nimport anorm.{SQL, SqlParser}\nimport com.mlasaf.dto._\nimport java.util.Date\n");
    outputContent.write("\n");
    outputContent.write("\n");
    outputContent.write(" class DaoRests extends RestBase {\n\n \n  def initialize() : Unit = { \n");
    // GETs
    cols.map(x => x.TABLE_NAME).distinct.sorted.foreach( tableName => {
      val isTable = !tableName.startsWith("v");
      val objName = tableName.charAt(0).toUpper + tableName.substring(1);
      val dtoName = objName + "Dto";
      val daoClassName = objName + "Dao";
      val daoObjName = tableName + "Dao";
      val listDefName = "get" + objName + "sList";
      val countDefName = "get" + objName + "sCount";
      outputContent.write("      spark.Spark.get(\"/" + tableName + "\", (req: spark.Request, resp: spark.Response) => \" [ \" + parentRest.parentContext.daoFactory.daos." + daoObjName + "." + listDefName + "().map(a => a.toJson()).mkString(\",\") + \" ] \" ); ");
      outputContent.write("\n");
      outputContent.write("      spark.Spark.get(\"/" + tableName + "-count\", (req: spark.Request, resp: spark.Response) => \" { \\\"count\\\":\" + parentRest.parentContext.daoFactory.daos." + daoObjName + "." + countDefName + "() + \" } \" ); ");
      outputContent.write("\n");
    });
    //GETs with parameters
    // TODO: write code to generage GETs with parameters - by PK, by Name, by insertedRowDate
    // POSTS
    outputContent.write("\n");
    outputContent.write("  } ");
    outputContent.write("\n");
    outputContent.write("} ");
    outputContent.write("\n");

    outputContent.close();
    connmssql.close();
  }
}
